{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d158d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "def IrisLocalization(images):\n",
    "    #convert image to a color image\n",
    "    target = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in images]\n",
    "    boundary=[] #initialize empty list that will eventually contain all the images with boundaries\n",
    "    centers=[] #initialize empty list that will contain the centers of the boundary circles\n",
    "    for img in target:\n",
    "        \n",
    "        draw_img=img\n",
    "        \n",
    "        # remove noise by blurring the image\n",
    "        blur = cv2.bilateralFilter(img, 9,75,75)\n",
    "        img=blur\n",
    "        \n",
    "        #estimate the center of pupil\n",
    "        horizontalProjection = np.mean(img,0);\n",
    "        verticalProjection = np.mean(img,1);\n",
    "        center_x=horizontalProjection.argmin()\n",
    "        center_y=verticalProjection.argmin()\n",
    "        \n",
    "        #recalculate of pupil by concentrating on a 120X120 area\n",
    "        centrecrop_x = img[center_x-60:center_x+60]\n",
    "        centrecrop_y = img[center_y-60:center_y+60]\n",
    "        horizontalProjection = np.mean(centrecrop_y,0);\n",
    "        verticalProjection = np.mean(centrecrop_x,0);\n",
    "        crop_center_x=horizontalProjection.argmin()\n",
    "        crop_center_y=verticalProjection.argmin()\n",
    "\n",
    "        cimg=img.copy()\n",
    "        cv2.circle(cimg,(crop_center_x,crop_center_y),1,(255,0,0),2)\n",
    "\n",
    "        #apply Canny edge detector on the masked image\n",
    "        maskimage = cv2.inRange(img, 0, 70)\n",
    "        output = cv2.bitwise_and(img, maskimage)\n",
    "        edged = cv2.Canny(output, 100, 220)\n",
    "        \n",
    "        # Apply Hough transform to find potential boundaries of pupil\n",
    "        circles = cv2.HoughCircles(edged, cv2.HOUGH_GRADIENT, 10, 100)\n",
    "        \n",
    "        #define the center of the pupil\n",
    "        a = (crop_center_x,crop_center_y)\n",
    "        \n",
    "        out = img.copy()\n",
    "        min_dst=math.inf\n",
    "        for i in circles[0]:\n",
    "            #find the circle whose center is closest to the approx center found above\n",
    "            b=(i[0],i[1])\n",
    "            dst = distance.euclidean(a, b)\n",
    "            if dst<min_dst:\n",
    "                min_dst=dst\n",
    "                k=i\n",
    "                \n",
    "        #draw the inner boundary\n",
    "        cv2.circle(draw_img,  (int(k[0]), int(k[1])), int(k[2]), (255, 0, 0), 3)\n",
    "\n",
    "        pupil=circles[0][0]\n",
    "        radius_pupil = int(k[2])\n",
    "        \n",
    "        #draw the outer boundary, which is approximately found to be at a distance 53 from the inner boundary \n",
    "        cv2.circle(draw_img,  (int(k[0]), int(k[1])), int(radius_pupil+53), (255, 0, 0), 3)\n",
    "        boundary.append(draw_img)\n",
    "        centers.append([k[0],k[1],k[2]])\n",
    "    return boundary,centers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f60128d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "def IrisNormalization(boundary,centers):\n",
    "    target = [img for img in boundary]\n",
    "    normalized=[]\n",
    "    cent=0\n",
    "    for img in target:\n",
    "        #load pupil centers and radius of inner circles\n",
    "        center_x = centers[cent][0]\n",
    "        center_y = centers[cent][1]\n",
    "        radius_pupil=int(centers[cent][2])\n",
    "        \n",
    "        iris_radius = 53 # width of space between inner and outer boundary\n",
    "    \n",
    "        #define equally spaced interval to iterate over\n",
    "        nsamples = 360\n",
    "        samples = np.linspace(0,2*np.pi, nsamples)[:-1]\n",
    "        polar = np.zeros((iris_radius, nsamples))\n",
    "        for r in range(iris_radius):\n",
    "            for theta in samples:\n",
    "                #get x and y for values on inner boundary\n",
    "                x = (r+radius_pupil)*np.cos(theta)+center_x\n",
    "                y = (r+radius_pupil)*np.sin(theta)+center_y\n",
    "                x=int(x)\n",
    "                y=int(y)\n",
    "                try:\n",
    "                #convert coordinates\n",
    "                    polar[r][int((theta*nsamples)/(2*np.pi))] = img[y][x]\n",
    "                except IndexError: #ignores values which lie out of bounds\n",
    "                    pass\n",
    "                continue\n",
    "        res = cv2.resize(polar,(512,64))\n",
    "        normalized.append(res)\n",
    "        cent+=1\n",
    "    return normalized #returns a list of 64x512 normalized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4feb16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "#Equalizes the histogram of the image\n",
    "def ImageEnhancement(normalized):\n",
    "    enhanced=[]\n",
    "    for res in normalized:\n",
    "        res = res.astype(np.uint8)\n",
    "        im=cv2.equalizeHist(res)\n",
    "        enhanced.append(im)\n",
    "    return enhanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d46878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy import signal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "#modulating function as defined in paper\n",
    "def m(x ,y, f):\n",
    "    val = np.cos(2*np.pi*f*math.sqrt(x **2 + y**2))\n",
    "    return val\n",
    "#spatial filter as defined in paper\n",
    "def gabor(x, y, dx, dy, f):\n",
    "    gb = (1/(2*math.pi*dx*dy))*np.exp(-0.5*(x**2 / dx**2 + y**2 / dy**2)) * m(x, y, f)\n",
    "    return gb\n",
    "\n",
    "#function to calculate spatial filter over 8x8 blocks\n",
    "def spatial(f,dx,dy):\n",
    "    sfilter=np.zeros((8,8))\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            sfilter[i,j]=gabor((-4+j),(-4+i),dx,dy,f)\n",
    "    return sfilter\n",
    "\n",
    "def get_vec(convolvedtrain1,convolvedtrain2):\n",
    "    feature_vec=[]\n",
    "    for i in range(6):\n",
    "            for j in range(64):\n",
    "                #Run 8 by 8 filtered block iteratively over the entire image\n",
    "                start_height = i*8\n",
    "                end_height = start_height+8\n",
    "                start_wid = j*8\n",
    "                end_wid = start_wid+8\n",
    "                grid1 = convolvedtrain1[start_height:end_height, start_wid:end_wid]\n",
    "                grid2 = convolvedtrain2[start_height:end_height, start_wid:end_wid]\n",
    "\n",
    "                # Channel 1\n",
    "                absolute = np.absolute(grid1)\n",
    "                # mean\n",
    "                mean = np.mean(absolute)\n",
    "                feature_vec.append(mean)\n",
    "                #deviation\n",
    "                std = np.mean(np.absolute(absolute-mean))\n",
    "                feature_vec.append(std)\n",
    "\n",
    "                # Channel 2\n",
    "                absolute = np.absolute(grid2)\n",
    "                # mean\n",
    "                mean = np.mean(absolute)\n",
    "                feature_vec.append(mean)\n",
    "                #deviation\n",
    "                std = np.mean(np.absolute(absolute-mean))\n",
    "                feature_vec.append(std)\n",
    "\n",
    "    return feature_vec\n",
    "\n",
    "def FeatureExtraction(enhanced):\n",
    "    con1=[]\n",
    "    con2=[]\n",
    "    #get spatial filters\n",
    "    filter1=spatial(0.67,3,1.5)\n",
    "    filter2=spatial(0.67,4,1.5) \n",
    "    \n",
    "    feature_vector=[]\n",
    "    \n",
    "    for i in range(len(enhanced)):\n",
    "        img=enhanced[i]\n",
    "        #define a 48x512 region over which the filters are applied\n",
    "        img_roi=img[:48,:]\n",
    "        \n",
    "        filtered1=scipy.signal.convolve2d(img_roi,filter1,mode='same')\n",
    "        filtered2=scipy.signal.convolve2d(img_roi,filter2,mode='same')\n",
    "        \n",
    "        con1.append(filtered1)\n",
    "        con2.append(filtered2)\n",
    "        fv=get_vec(filtered1,filtered2)\n",
    "        feature_vector.append(fv)\n",
    "    return feature_vector #each feature vector has a dimension of 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "141410c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "from decimal import Decimal\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def nth_root(value, n_root):\n",
    " \n",
    "    root_value = 1/float(n_root)\n",
    "    return round (Decimal(value) ** Decimal(root_value),3)\n",
    "def square_rooted(x):\n",
    " \n",
    "    return round(sqrt(sum([a*a for a in x])),3)\n",
    "\n",
    "def IrisMatching(feature_vector_train,feature_vector_test):\n",
    "    eu_dist=[]\n",
    "    mh_dist=[]\n",
    "    mk_dist=[]\n",
    "    cos_dist=[]\n",
    "    can_dist=[]\n",
    "    for test in feature_vector_test:\n",
    "        y=test\n",
    "        for train in feature_vector_train:\n",
    "            x=train\n",
    "            #print(len(x))\n",
    "            eu_dist.append(sqrt(sum(pow(a-b,2) for a, b in zip(x, y))))\n",
    "            mh_dist.append(sum(abs(a-b) for a,b in zip(x,y)))\n",
    "            mk_dist.append(nth_root(sum(pow(abs(a-b),3) for a,b in zip(x, y)),3))\n",
    "            numerator = sum(a*b for a,b in zip(x,y))\n",
    "            denominator = square_rooted(x)*square_rooted(y)\n",
    "            cos_dist.append(round(numerator/float(denominator),3))\n",
    "            can_dist.append(distance.canberra(x,y))\n",
    "    return eu_dist,mh_dist,mk_dist,cos_dist,can_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e7edc60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data processed.\n",
      "Testing data processed.\n",
      "0.9632499999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\njklkkx\\nprint(\"Begin Matching test data with the train data\")\\nfor i in range(108):\\n    path=\"D:/College/BE project/Dataset/CASIA Iris Image Database (version 1.0)/\"\\n    no=\\'{0:03d}\\'.format(i+1)\\n    p1=\"/1/*.bmp\"\\n    p2=\"/2/*.bmp\"\\n    \\n    images_train = [cv2.imread(file) for file in sorted(glob.glob(path+no+p1))]\\n    boundary_train,centers_train=IrisLocalization(images_train)\\n    normalized_train=IrisNormalization(boundary_train,centers_train)\\n    enhanced_train=ImageEnhancement(normalized_train)\\n    feature_vector_train=FeatureExtraction(enhanced_train)\\n    #print(\"Training data processed.\")\\n\\n    images_test = [cv2.imread(file) for file in sorted(glob.glob(path+no+p2))]\\n    #running Localization, Normalization,Enhancement and Feature Extraction on all the testing images\\n    boundary_test,centers_test=IrisLocalization(images_test)\\n    normalized_test=IrisNormalization(boundary_test,centers_test)\\n    enhanced_test=ImageEnhancement(normalized_test)\\n    feature_vector_test=FeatureExtraction(enhanced_test)\\n    #print(\"Testing data processed.\")\\n\\n    eu_dist,mh_dist,mk_dist,cos_dist,can_dist=IrisMatching(feature_vector_train,feature_vector_test)\\n    print(i+1,\" \",mean(cos_dist))\\n    \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from statistics import mean\n",
    "from scipy import signal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "'''TRAINING'''\n",
    "#reading the training images from the CASIA dataset\n",
    "\n",
    "images_train = [cv2.imread(file) for file in sorted(glob.glob('D:/College/BE project/Dataset/CASIA Iris Image Database (version 1.0)/051/1/*.bmp'))]\n",
    "\n",
    "#running Localization, Normalization,Enhancement and Feature Extraction on all the training images\n",
    "boundary_train,centers_train=IrisLocalization(images_train)\n",
    "normalized_train=IrisNormalization(boundary_train,centers_train)\n",
    "enhanced_train=ImageEnhancement(normalized_train)\n",
    "feature_vector_train=FeatureExtraction(enhanced_train)\n",
    "print(\"Training data processed.\")\n",
    "\n",
    "#print(images_train)\n",
    "\n",
    "#TESTING\n",
    "#reading the testing images from the CASIA dataset\n",
    "images_test = [cv2.imread(file) for file in sorted(glob.glob('D:/College/BE project/Dataset/CASIA Iris Image Database (version 1.0)/016/2/*.bmp'))]\n",
    "#running Localization, Normalization,Enhancement and Feature Extraction on all the testing images\n",
    "boundary_test,centers_test=IrisLocalization(images_test)\n",
    "normalized_test=IrisNormalization(boundary_test,centers_test)\n",
    "enhanced_test=ImageEnhancement(normalized_test)\n",
    "feature_vector_test=FeatureExtraction(enhanced_test)\n",
    "print(\"Testing data processed.\")\n",
    "#print(eu_dist)\n",
    "#print(mh_dist)\n",
    "#print(mk_dist)\n",
    "#print(cos_dist)\n",
    "#print(can_dist)\n",
    "eu_dist,mh_dist,mk_dist,cos_dist,can_dist=IrisMatching(feature_vector_train,feature_vector_test)\n",
    "print(mean(cos_dist))\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "jklkkx\n",
    "print(\"Begin Matching test data with the train data\")\n",
    "for i in range(108):\n",
    "    path=\"D:/College/BE project/Dataset/CASIA Iris Image Database (version 1.0)/\"\n",
    "    no='{0:03d}'.format(i+1)\n",
    "    p1=\"/1/*.bmp\"\n",
    "    p2=\"/2/*.bmp\"\n",
    "    \n",
    "    images_train = [cv2.imread(file) for file in sorted(glob.glob(path+no+p1))]\n",
    "    boundary_train,centers_train=IrisLocalization(images_train)\n",
    "    normalized_train=IrisNormalization(boundary_train,centers_train)\n",
    "    enhanced_train=ImageEnhancement(normalized_train)\n",
    "    feature_vector_train=FeatureExtraction(enhanced_train)\n",
    "    #print(\"Training data processed.\")\n",
    "\n",
    "    images_test = [cv2.imread(file) for file in sorted(glob.glob(path+no+p2))]\n",
    "    #running Localization, Normalization,Enhancement and Feature Extraction on all the testing images\n",
    "    boundary_test,centers_test=IrisLocalization(images_test)\n",
    "    normalized_test=IrisNormalization(boundary_test,centers_test)\n",
    "    enhanced_test=ImageEnhancement(normalized_test)\n",
    "    feature_vector_test=FeatureExtraction(enhanced_test)\n",
    "    #print(\"Testing data processed.\")\n",
    "\n",
    "    eu_dist,mh_dist,mk_dist,cos_dist,can_dist=IrisMatching(feature_vector_train,feature_vector_test)\n",
    "    print(i+1,\" \",mean(cos_dist))\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef709e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48f387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "535e4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "def dim_reduction(feature_vector_train,feature_vector_test,components):\n",
    "    '''TRAINING'''\n",
    "    ft_train=feature_vector_train\n",
    "    \n",
    "    #get the classes of all training feature vectors\n",
    "    y_train=[]\n",
    "    for i in range(0,108):\n",
    "        for k in range(0,3):\n",
    "            y_train.append(i+1)\n",
    "    #y_train=[5,5,5]\n",
    "    y_train=np.array(y_train)\n",
    "    \n",
    "    '''print(\"h\")\n",
    "    print(ft_train)\n",
    "    print(\"j\")\n",
    "    print(y_train)'''\n",
    "    #fit the LDA model on training data with n components\n",
    "    sklearn_lda = LDA(n_components=components)\n",
    "    sklearn_lda.fit(ft_train,y_train)\n",
    "    \n",
    "    #transform the traning data\n",
    "    red_train=sklearn_lda.transform(ft_train)\n",
    "    \n",
    "    '''TESTING'''\n",
    "    ft_test=feature_vector_test\n",
    "    \n",
    "    #transform the testing data\n",
    "    red_test=sklearn_lda.transform(ft_test)\n",
    "    \n",
    "    \n",
    "    #get a list of predicted values for the testing data to calculate ROC\n",
    "    y_pred=sklearn_lda.predict(ft_test)\n",
    "    \n",
    "    #return transformed training and testing data, and the testing classes and predicted values for ROC\n",
    "    return red_train,red_test\n",
    "\n",
    "\n",
    "def IrisMatching(feature_vector_train,feature_vector_test,components,flag):\n",
    "    \n",
    "    #if flag is 1, we do not need to reduce dimesionality otherwise we call the dim_reduction function\n",
    "    if flag==1:\n",
    "        red_train=feature_vector_train\n",
    "        red_test=feature_vector_test\n",
    "        \n",
    "    elif flag==0:\n",
    "        red_train,red_test=dim_reduction(feature_vector_train,feature_vector_test,components)\n",
    "\n",
    "\n",
    "    arr_f=red_test #test\n",
    "    arr_fi=red_train #train\n",
    "    \n",
    "    index_L1=[]\n",
    "    index_L2=[]\n",
    "    index_cosine=[]\n",
    "    min_cosine=[]\n",
    "    \n",
    "    #this loop iterates over each test image\n",
    "    for i in range(0,len(arr_f)):\n",
    "        L1=[]\n",
    "        L2=[]\n",
    "        Cosine=[]\n",
    "        \n",
    "        #this loop iterates over every training image - to be compared to each test image\n",
    "        for j in range(0,len(arr_fi)):\n",
    "            f=arr_f[i]\n",
    "            fi=arr_fi[j]\n",
    "            sumL1=0 #L1 distance\n",
    "            sumL2=0 #L2 distance\n",
    "            sumcos1=0\n",
    "            sumcos2=0\n",
    "            cosinedist=0 #cosine distance\n",
    "            \n",
    "            #calculate L1 and L2 using the formulas in the paper\n",
    "            for l in range(0,len(f)):\n",
    "                sumL1+=abs(f[l]-fi[l])\n",
    "                sumL2+=math.pow((f[l]-fi[l]),2)\n",
    "            \n",
    "            \n",
    "            #calculate sum of squares of all features for cosine distance\n",
    "            for k in range(0,len(f)):\n",
    "                sumcos1+=math.pow(f[k],2)\n",
    "                sumcos2+=math.pow(fi[k],2)\n",
    "                \n",
    "            \n",
    "            #calculate cosine distance using sumcos1 and sumcos2 calculated above\n",
    "            cosinedist=1-((np.matmul(np.transpose(f),fi))/(math.pow(sumcos1,0.5)*math.pow(sumcos2,0.5)))\n",
    "            \n",
    "            L1.append(sumL1)\n",
    "            L2.append(sumL2)\n",
    "            Cosine.append(cosinedist)\n",
    "        #get minimum values for L1 L2 and cosine distance for each test image and store their index\n",
    "        index_L1.append(L1.index(min(L1)))\n",
    "        index_L2.append(L2.index(min(L2)))\n",
    "        index_cosine.append(Cosine.index(min(Cosine)))\n",
    "        min_cosine.append(min(Cosine))\n",
    "        print(\"leng\",len(L1))\n",
    "        print(\"index\")\n",
    "        print(index_L1)\n",
    "        print(index_L2)\n",
    "        print(index_cosine)\n",
    "        \n",
    "        \n",
    "        \n",
    "    match=0\n",
    "    count=0\n",
    "    \n",
    "    #stores final matching - correct(1) or incorrect (0)\n",
    "    match_L1=[]\n",
    "    match_L2=[]\n",
    "    match_cosine=[]\n",
    "    match_cosine_ROC=[]\n",
    "    \n",
    "    #calculating matching of the test set according to the ROC thresholds\n",
    "    thresh=[0.4,0.5,0.6]\n",
    "    \n",
    "    for x in range(0,len(thresh)):\n",
    "        match_ROC=[]\n",
    "        for y in range(0,len(min_cosine)):\n",
    "            if min_cosine[y]<=thresh[x]:\n",
    "                match_ROC.append(1)\n",
    "            else:\n",
    "                match_ROC.append(0)\n",
    "        match_cosine_ROC.append(match_ROC)\n",
    "        \n",
    "    \n",
    "    for k in range(0,len(index_L1)):\n",
    "        '''count goes from 0 to 3 because we compare the indexes obtained for the first 4 images of the test data\n",
    "        to the indexes of the first 3 images of \n",
    "        the train data (for which match is incremented by 3 everytime count exceeds the value of 3)'''\n",
    "        if count<4:\n",
    "            count+=1\n",
    "        else:\n",
    "            match+=3\n",
    "            count=1\n",
    "            \n",
    "        '''check if matching is done correctly (1) or not (0) for L1 L2 and cosine distance and accordingly update\n",
    "        the arrays match_L1,match_L2,match_cosine'''\n",
    "        if index_L1[k] in range(match,match+3):\n",
    "                match_L1.append(1)\n",
    "        else:\n",
    "            match_L1.append(0)\n",
    "        if index_L2[k] in range(match,match+3):\n",
    "            match_L2.append(1)\n",
    "        else:\n",
    "            match_L2.append(0)\n",
    "        if index_cosine[k] in range(match,match+3):\n",
    "            match_cosine.append(1)\n",
    "        else:\n",
    "            match_cosine.append(0)\n",
    "    #reuturns the matching arrays, and test calsses and predicted values to calculate ROC\n",
    "    print(\"match\")\n",
    "    print(match_L1)\n",
    "    print(match_L2)\n",
    "    print(match_cosine)\n",
    "    \n",
    "    return match_L1,match_L2,match_cosine,match_cosine_ROC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6656775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "def PerformanceEvaluation(match_L1,match_L2,match_cosine):\n",
    "    \n",
    "    #storing only those elements that are correctly matched\n",
    "    correct_L1 = [l for l in match_L1 if l==1]\n",
    "    correct_L2 = [l for l in match_L2 if l==1]\n",
    "    correct_cosine = [l for l in match_cosine if l==1]\n",
    "    \n",
    "    \n",
    "    #calculating the correct recognition rates for L1,L2 and cosine similarity\n",
    "    crr_L1=len(correct_L1)/len(match_L1)\n",
    "    crr_L2=len(correct_L2)/len(match_L2)\n",
    "    crr_cosine=len(correct_cosine)/len(match_cosine)\n",
    "    \n",
    "    \n",
    "    return crr_L1*100,crr_L2*100,crr_cosine*100 #return CRR percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4da6d230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data processed.\n",
      "Testing data processed.\n",
      "0\n",
      "1\n",
      "Begin Matching test data with the train data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03mfor comp in components:\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    match_cosine_ROC.append(comp_match_cosine_ROC)\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m    print(comp_match_L1,comp_match_L2,comp_match_cosine,comp_match_cosine_ROC)'''\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m#Performing Matching and calculating CRR score for the original feature vector (without dimensionality reduction)\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m orig_match_L1,orig_match_L2,orig_match_cosine,orig_match_cosine_ROC\u001b[38;5;241m=\u001b[39m\u001b[43mIrisMatching\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_vector_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeature_vector_test\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m orig_crr_L1,orig_crr_L2,orig_crr_cosine\u001b[38;5;241m=\u001b[39mPerformanceEvaluation(orig_match_L1,orig_match_L2,orig_match_cosine)  \n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted Matching\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mIrisMatching\u001b[1;34m(feature_vector_train, feature_vector_test, components, flag)\u001b[0m\n\u001b[0;32m    102\u001b[0m     Cosine\u001b[38;5;241m.\u001b[39mappend(cosinedist)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m#get minimum values for L1 L2 and cosine distance for each test image and store their index\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m index_L1\u001b[38;5;241m.\u001b[39mappend(L1\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mL1\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    105\u001b[0m index_L2\u001b[38;5;241m.\u001b[39mappend(L2\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmin\u001b[39m(L2)))\n\u001b[0;32m    106\u001b[0m index_cosine\u001b[38;5;241m.\u001b[39mappend(Cosine\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmin\u001b[39m(Cosine)))\n",
      "\u001b[1;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy import signal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\"\"\"from IrisLocalization import IrisLocalization\n",
    "from IrisNormalization import IrisNormalization\n",
    "from ImageEnhancement import ImageEnhancement\n",
    "from FeatureExtraction import FeatureExtraction\n",
    "from IrisMatching import IrisMatching\n",
    "from PerformanceEvaluation import PerformanceEvaluation\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "'''TRAINING'''\n",
    "#reading the training images from the CASIA dataset\n",
    "\n",
    "images_train = [cv2.imread(file) for file in sorted(glob.glob('D:/College/BE project/Dataset/CASIA Iris Image Database (version 1.0)/2/1/*.bmp'))]\n",
    "\n",
    "#running Localization, Normalization,Enhancement and Feature Extraction on all the training images\n",
    "boundary_train,centers_train=IrisLocalization(images_train)\n",
    "normalized_train=IrisNormalization(boundary_train,centers_train)\n",
    "enhanced_train=ImageEnhancement(normalized_train)\n",
    "feature_vector_train=FeatureExtraction(enhanced_train)\n",
    "print(\"Training data processed.\")\n",
    "\n",
    "#print(images_train)\n",
    "\n",
    "'''TESTING'''\n",
    "#reading the testing images from the CASIA dataset\n",
    "images_test = [cv2.imread(file) for file in sorted(glob.glob('D:/College/BE project/Dataset/CASIA Iris Image Database (version 1.0)/002/2/002_2_3.bmp'))]\n",
    "#running Localization, Normalization,Enhancement and Feature Extraction on all the testing images\n",
    "boundary_test,centers_test=IrisLocalization(images_test)\n",
    "normalized_test=IrisNormalization(boundary_test,centers_test)\n",
    "enhanced_test=ImageEnhancement(normalized_test)\n",
    "feature_vector_test=FeatureExtraction(enhanced_test)\n",
    "print(\"Testing data processed.\")\n",
    "\n",
    "print(len(feature_vector_train))\n",
    "print(len(feature_vector_test))\n",
    "\n",
    "crr_L1=[]\n",
    "crr_L2=[]\n",
    "crr_cosine=[]\n",
    "y_test=[]\n",
    "y_pred=[]\n",
    "match_cosine=[]\n",
    "match_cosine_ROC=[]\n",
    "\n",
    "#Performing Matching and CRR scores for 10,40,60,80,90,107 number of dimensions in the reduced feature vector\n",
    "components=[10,40,60,80,90,107]\n",
    "\n",
    "print(\"Begin Matching test data with the train data\")\n",
    "'''\n",
    "for comp in components:\n",
    "    \n",
    "    #Running matching for all the dimensions specified in \"components\" \n",
    "    comp_match_L1,comp_match_L2,comp_match_cosine,comp_match_cosine_ROC=IrisMatching(feature_vector_train,feature_vector_test,comp,1)\n",
    "    \n",
    "    #Calculating CRR for all the dimensions specified in \"components\" \n",
    "    comp_crr_L1,comp_crr_L2,comp_crr_cosine=PerformanceEvaluation(comp_match_L1,comp_match_L2,comp_match_cosine)\n",
    "    \n",
    "    #combining the results of all the dimensional feature vector into one array\n",
    "    crr_L1.append(comp_crr_L1)\n",
    "    crr_L2.append(comp_crr_L2)\n",
    "    crr_cosine.append(comp_crr_cosine)\n",
    "    match_cosine.append(comp_match_cosine)\n",
    "    match_cosine_ROC.append(comp_match_cosine_ROC)\n",
    "    print(comp_match_L1,comp_match_L2,comp_match_cosine,comp_match_cosine_ROC)'''\n",
    "\n",
    "\n",
    "#Performing Matching and calculating CRR score for the original feature vector (without dimensionality reduction)\n",
    "orig_match_L1,orig_match_L2,orig_match_cosine,orig_match_cosine_ROC=IrisMatching(feature_vector_train,feature_vector_test,0,1)\n",
    "orig_crr_L1,orig_crr_L2,orig_crr_cosine=PerformanceEvaluation(orig_match_L1,orig_match_L2,orig_match_cosine)  \n",
    "print(\"Completed Matching\")\n",
    "#print(orig_match_L1,orig_match_L2,orig_match_cosine,orig_match_cosine_ROC)\n",
    "\"\"\"\n",
    "hhhc\n",
    "#Table for CRR rates for the original and reduced feature set(components=107)\n",
    "print('\\n\\n\\n')\n",
    "dict={'Similarity Measure':['L1','L2','Cosine Distance'],'CRR for Original Feature Set':[orig_crr_L1,orig_crr_L2,orig_crr_cosine],'CRR for Reduced Feature Set (107)':[crr_L1[5],crr_L2[5],crr_cosine[5]]}\n",
    "table=pd.DataFrame(dict)\n",
    "print(\"Recognition results using Different Similarity Measures : \\n\")\n",
    "print(table.iloc[0],\"\\n\")\n",
    "print(table.iloc[1],\"\\n\")\n",
    "print(table.iloc[2])\n",
    "\n",
    "\n",
    "# Plotting the incresing CRR for cosine similarity with the incresing dimensionality\n",
    "plt.plot(components,crr_cosine)\n",
    "plt.axis([10,107,0,100])\n",
    "plt.ylabel('Correct Recognition Rate (Cosine)')\n",
    "plt.xlabel('Dimensionality of the feature vector')\n",
    "plt.title('Recognition Results')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Calculating the false positive and the true positive rates for the data\n",
    "#We have taken match_cosine[5] because the 5th instance of the array is for the 107 reduced feature dimension\n",
    "fmr_all=[]\n",
    "fnmr_all=[]\n",
    "\n",
    "for q in range(0,3):\n",
    "    false_accept=0\n",
    "    false_reject=0\n",
    "    num_1=len([i for i in match_cosine_ROC[5][q] if i==1])\n",
    "    num_0=len([i for i in match_cosine_ROC[5][q] if i==0])\n",
    "\n",
    "    for p in range(0,len(match_cosine[5])):\n",
    "        if match_cosine[5][p]==0 and match_cosine_ROC[5][q][p]==1:\n",
    "            false_accept+=1\n",
    "        if match_cosine[5][p]==1 and match_cosine_ROC[5][q][p]==0:\n",
    "            false_reject+=1\n",
    "    fmr=false_accept/num_1\n",
    "    fnmr=false_reject/num_0\n",
    "    thresh=[0.4,0.5,0.6]\n",
    "    fmr_all.append(fmr)\n",
    "    fnmr_all.append(fnmr)\n",
    "\n",
    "\n",
    "dict1={'Threshold':thresh,'FMR':fmr_all,'FNMR':fnmr_all}\n",
    "roc_table=pd.DataFrame(dict1)\n",
    "print(\"ROC Measures : \\n\")\n",
    "print(roc_table.iloc[0],\"\\n\")\n",
    "print(roc_table.iloc[1],\"\\n\")\n",
    "print(roc_table.iloc[2])\n",
    "\n",
    "\n",
    "#Plotting the ROC Curve\n",
    "plt.plot(fnmr_all,fmr_all)\n",
    "plt.title('ROC Curve')\n",
    "plt.ylabel('False Non-Match Rate')\n",
    "plt.xlabel('False Match Rate')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89167e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
