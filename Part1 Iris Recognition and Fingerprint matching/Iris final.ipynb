{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4b162d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "def IrisLocalization(images):\n",
    "    #convert image to a color image\n",
    "    target = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in images]\n",
    "    boundary=[] #initialize empty list that will eventually contain all the images with boundaries\n",
    "    centers=[] #initialize empty list that will contain the centers of the boundary circles\n",
    "    for img in target:\n",
    "        \n",
    "        draw_img=img\n",
    "        \n",
    "        # remove noise by blurring the image\n",
    "        blur = cv2.bilateralFilter(img, 9,75,75)\n",
    "        img=blur\n",
    "        \n",
    "        #estimate the center of pupil\n",
    "        horizontalProjection = np.mean(img,0);\n",
    "        verticalProjection = np.mean(img,1);\n",
    "        center_x=horizontalProjection.argmin()\n",
    "        center_y=verticalProjection.argmin()\n",
    "        \n",
    "        #recalculate of pupil by concentrating on a 120X120 area\n",
    "        centrecrop_x = img[center_x-60:center_x+60]\n",
    "        centrecrop_y = img[center_y-60:center_y+60]\n",
    "        horizontalProjection = np.mean(centrecrop_y,0);\n",
    "        verticalProjection = np.mean(centrecrop_x,0);\n",
    "        crop_center_x=horizontalProjection.argmin()\n",
    "        crop_center_y=verticalProjection.argmin()\n",
    "\n",
    "        cimg=img.copy()\n",
    "        cv2.circle(cimg,(crop_center_x,crop_center_y),1,(255,0,0),2)\n",
    "\n",
    "        #apply Canny edge detector on the masked image\n",
    "        maskimage = cv2.inRange(img, 0, 70)\n",
    "        output = cv2.bitwise_and(img, maskimage)\n",
    "        edged = cv2.Canny(output, 100, 220)\n",
    "        \n",
    "        # Apply Hough transform to find potential boundaries of pupil\n",
    "        circles = cv2.HoughCircles(edged, cv2.HOUGH_GRADIENT, 10, 100)\n",
    "        \n",
    "        #define the center of the pupil\n",
    "        a = (crop_center_x,crop_center_y)\n",
    "        \n",
    "        out = img.copy()\n",
    "        min_dst=math.inf\n",
    "        for i in circles[0]:\n",
    "            #find the circle whose center is closest to the approx center found above\n",
    "            b=(i[0],i[1])\n",
    "            dst = distance.euclidean(a, b)\n",
    "            if dst<min_dst:\n",
    "                min_dst=dst\n",
    "                k=i\n",
    "                \n",
    "        #draw the inner boundary\n",
    "        cv2.circle(draw_img,  (int(k[0]), int(k[1])), int(k[2]), (255, 0, 0), 3)\n",
    "\n",
    "        pupil=circles[0][0]\n",
    "        radius_pupil = int(k[2])\n",
    "        \n",
    "        #draw the outer boundary, which is approximately found to be at a distance 53 from the inner boundary \n",
    "        cv2.circle(draw_img,  (int(k[0]), int(k[1])), int(radius_pupil+53), (255, 0, 0), 3)\n",
    "        boundary.append(draw_img)\n",
    "        centers.append([k[0],k[1],k[2]])\n",
    "    return boundary,centers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "466b5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "def IrisNormalization(boundary,centers):\n",
    "    target = [img for img in boundary]\n",
    "    normalized=[]\n",
    "    cent=0\n",
    "    for img in target:\n",
    "        #load pupil centers and radius of inner circles\n",
    "        center_x = centers[cent][0]\n",
    "        center_y = centers[cent][1]\n",
    "        radius_pupil=int(centers[cent][2])\n",
    "        \n",
    "        iris_radius = 53 # width of space between inner and outer boundary\n",
    "    \n",
    "        #define equally spaced interval to iterate over\n",
    "        nsamples = 360\n",
    "        samples = np.linspace(0,2*np.pi, nsamples)[:-1]\n",
    "        polar = np.zeros((iris_radius, nsamples))\n",
    "        for r in range(iris_radius):\n",
    "            for theta in samples:\n",
    "                #get x and y for values on inner boundary\n",
    "                x = (r+radius_pupil)*np.cos(theta)+center_x\n",
    "                y = (r+radius_pupil)*np.sin(theta)+center_y\n",
    "                x=int(x)\n",
    "                y=int(y)\n",
    "                try:\n",
    "                #convert coordinates\n",
    "                    polar[r][int((theta*nsamples)/(2*np.pi))] = img[y][x]\n",
    "                except IndexError: #ignores values which lie out of bounds\n",
    "                    pass\n",
    "                continue\n",
    "        res = cv2.resize(polar,(512,64))\n",
    "        normalized.append(res)\n",
    "        cent+=1\n",
    "    return normalized #returns a list of 64x512 normalized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ca8c6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "#Equalizes the histogram of the image\n",
    "def ImageEnhancement(normalized):\n",
    "    enhanced=[]\n",
    "    for res in normalized:\n",
    "        res = res.astype(np.uint8)\n",
    "        im=cv2.equalizeHist(res)\n",
    "        enhanced.append(im)\n",
    "    return enhanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9326cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy import signal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "#modulating function as defined in paper\n",
    "def m(x ,y, f):\n",
    "    val = np.cos(2*np.pi*f*math.sqrt(x **2 + y**2))\n",
    "    return val\n",
    "#spatial filter as defined in paper\n",
    "def gabor(x, y, dx, dy, f):\n",
    "    gb = (1/(2*math.pi*dx*dy))*np.exp(-0.5*(x**2 / dx**2 + y**2 / dy**2)) * m(x, y, f)\n",
    "    return gb\n",
    "\n",
    "#function to calculate spatial filter over 8x8 blocks\n",
    "def spatial(f,dx,dy):\n",
    "    sfilter=np.zeros((8,8))\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            sfilter[i,j]=gabor((-4+j),(-4+i),dx,dy,f)\n",
    "    return sfilter\n",
    "\n",
    "def get_vec(convolvedtrain1,convolvedtrain2):\n",
    "    feature_vec=[]\n",
    "    for i in range(6):\n",
    "            for j in range(64):\n",
    "                #Run 8 by 8 filtered block iteratively over the entire image\n",
    "                start_height = i*8\n",
    "                end_height = start_height+8\n",
    "                start_wid = j*8\n",
    "                end_wid = start_wid+8\n",
    "                grid1 = convolvedtrain1[start_height:end_height, start_wid:end_wid]\n",
    "                grid2 = convolvedtrain2[start_height:end_height, start_wid:end_wid]\n",
    "\n",
    "                # Channel 1\n",
    "                absolute = np.absolute(grid1)\n",
    "                # mean\n",
    "                mean = np.mean(absolute)\n",
    "                feature_vec.append(mean)\n",
    "                #deviation\n",
    "                std = np.mean(np.absolute(absolute-mean))\n",
    "                feature_vec.append(std)\n",
    "\n",
    "                # Channel 2\n",
    "                absolute = np.absolute(grid2)\n",
    "                # mean\n",
    "                mean = np.mean(absolute)\n",
    "                feature_vec.append(mean)\n",
    "                #deviation\n",
    "                std = np.mean(np.absolute(absolute-mean))\n",
    "                feature_vec.append(std)\n",
    "\n",
    "    return feature_vec\n",
    "\n",
    "def FeatureExtraction(enhanced):\n",
    "    con1=[]\n",
    "    con2=[]\n",
    "    #get spatial filters\n",
    "    filter1=spatial(0.67,3,1.5)\n",
    "    filter2=spatial(0.67,4,1.5) \n",
    "    \n",
    "    feature_vector=[]\n",
    "    \n",
    "    for i in range(len(enhanced)):\n",
    "        img=enhanced[i]\n",
    "        #define a 48x512 region over which the filters are applied\n",
    "        img_roi=img[:48,:]\n",
    "        \n",
    "        filtered1=scipy.signal.convolve2d(img_roi,filter1,mode='same')\n",
    "        filtered2=scipy.signal.convolve2d(img_roi,filter2,mode='same')\n",
    "        \n",
    "        con1.append(filtered1)\n",
    "        con2.append(filtered2)\n",
    "        fv=get_vec(filtered1,filtered2)\n",
    "        feature_vector.append(fv)\n",
    "    return feature_vector #each feature vector has a dimension of 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "541df119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "from decimal import Decimal\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def nth_root(value, n_root):\n",
    " \n",
    "    root_value = 1/float(n_root)\n",
    "    return round (Decimal(value) ** Decimal(root_value),3)\n",
    "def square_rooted(x):\n",
    " \n",
    "    return round(sqrt(sum([a*a for a in x])),3)\n",
    "\n",
    "def IrisMatching(feature_vector_train,feature_vector_test):\n",
    "    eu_dist=[]\n",
    "    mh_dist=[]\n",
    "    mk_dist=[]\n",
    "    cos_dist=[]\n",
    "    can_dist=[]\n",
    "    for test in feature_vector_test:\n",
    "        y=test\n",
    "        for train in feature_vector_train:\n",
    "            x=train\n",
    "            #print(len(x))\n",
    "            eu_dist.append(sqrt(sum(pow(a-b,2) for a, b in zip(x, y))))\n",
    "            mh_dist.append(sum(abs(a-b) for a,b in zip(x,y)))\n",
    "            mk_dist.append(nth_root(sum(pow(abs(a-b),3) for a,b in zip(x, y)),3))\n",
    "            numerator = sum(a*b for a,b in zip(x,y))\n",
    "            denominator = square_rooted(x)*square_rooted(y)\n",
    "            cos_dist.append(round(numerator/float(denominator),3))\n",
    "            can_dist.append(distance.canberra(x,y))\n",
    "    return eu_dist,mh_dist,mk_dist,cos_dist,can_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "77290e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerformanceEvaluation(means,threshold):\n",
    "    print(t)\n",
    "    arr=[]\n",
    "    for i in range(9):\n",
    "        l=[]\n",
    "        for j in range(9):\n",
    "            if means[i][j] >= t:\n",
    "                l.append(1)\n",
    "            else:\n",
    "                l.append(0)\n",
    "        arr.append(l)\n",
    "    print(arr)\n",
    "    \n",
    "    c,crr_cosine,wrong_rej=0,0,0\n",
    "    for a in arr:\n",
    "        c+=a.count(1)\n",
    "    #print(\"c= \",c)\n",
    "    crr_cosine=9/c\n",
    "    \n",
    "    fmr=(c-9)/c\n",
    "    \n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            if i==j and arr[i][j]==0:\n",
    "                wrong_rej+=1\n",
    "\n",
    "    fnmr=wrong_rej/(81-c)\n",
    "    \n",
    "    #print(arr)\n",
    "    return crr_cosine*100,fmr,fnmr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c5efad65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965\n",
      "[[1, 0, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 0, 0, 1, 0, 0, 0], [1, 0, 1, 0, 0, 1, 0, 1, 1], [0, 0, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0, 0], [1, 0, 1, 0, 0, 1, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
      "0.968\n",
      "[[1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
      "0.969\n",
      "[[1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
      "0.97\n",
      "[[1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
      "Performance evaluation\n",
      "ROC Measures : \n",
      "\n",
      "Threshold      0.965\n",
      "CRR cosine    36.000\n",
      "FMR            0.640\n",
      "FNMR           0.000\n",
      "Name: 0, dtype: float64 \n",
      "\n",
      "Threshold      0.968000\n",
      "CRR cosine    69.230769\n",
      "FMR            0.307692\n",
      "FNMR           0.000000\n",
      "Name: 1, dtype: float64 \n",
      "\n",
      "Threshold      0.969000\n",
      "CRR cosine    81.818182\n",
      "FMR            0.181818\n",
      "FNMR           0.000000\n",
      "Name: 2, dtype: float64 \n",
      "\n",
      "Threshold       0.97\n",
      "CRR cosine    100.00\n",
      "FMR             0.00\n",
      "FNMR            0.00\n",
      "Name: 3, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from statistics import mean\n",
    "from scipy import signal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "'''TRAINING\n",
    "#reading the training images from the CASIA dataset\n",
    "#find cust id fir pass ./custid/1/*.bmp\n",
    "images_train = [cv2.imread(file) for file in sorted(glob.glob('D:/College/BE project/Dataset/Iris final dataset/007/1/*.bmp'))]\n",
    "\n",
    "#running Localization, Normalization,Enhancement and Feature Extraction on all the training images\n",
    "boundary_train,centers_train=IrisLocalization(images_train)\n",
    "normalized_train=IrisNormalization(boundary_train,centers_train)\n",
    "enhanced_train=ImageEnhancement(normalized_train)\n",
    "feature_vector_train=FeatureExtraction(enhanced_train)\n",
    "print(\"Training data processed.\")\n",
    "\n",
    "\n",
    "#TESTING\n",
    "#reading the testing images from the CASIA dataset\n",
    "#take path from user(atm se)  ./custid/2custid_2_2.bmp\n",
    "images_test = [cv2.imread(file) for file in sorted(glob.glob('D:/College/BE project/Dataset/Iris final dataset/001/2/001_2_3.bmp'))]\n",
    "#running Localization, Normalization,Enhancement and Feature Extraction on all the testing images\n",
    "boundary_test,centers_test=IrisLocalization(images_test)\n",
    "normalized_test=IrisNormalization(boundary_test,centers_test)\n",
    "enhanced_test=ImageEnhancement(normalized_test)\n",
    "feature_vector_test=FeatureExtraction(enhanced_test)\n",
    "print(\"Testing data processed.\")\n",
    "\n",
    "eu_dist,mh_dist,mk_dist,cos_dist,can_dist=IrisMatching(feature_vector_train,feature_vector_test)\n",
    "print(cos_dist)\n",
    "print(\"mean - \",mean(cos_dist))\n",
    "if mean(cos_dist) >= 0.965:\n",
    "    print(\"Fingerprint matched\")\n",
    "else:\n",
    "    print(\"Fingerprint does't match\") \n",
    "    \n",
    "    \n",
    "if mean(cos_dist) >= 0.968:\n",
    "            l.append(\"1 \")\n",
    "        else:\n",
    "            l.append(\"0 \")\n",
    "'''\n",
    "means=[]\n",
    "for i in range(9):\n",
    "    l=[]\n",
    "    for j in range(9):\n",
    "        path=\"D:/College/BE project/Dataset/Iris final dataset - Copy/\"\n",
    "        no1='{0:03d}'.format(i+1)\n",
    "        no2='{0:03d}'.format(j+1)\n",
    "        p1=\"/1/*.bmp\"\n",
    "        p2=\"/2/*.bmp\"\n",
    "        \n",
    "        images_train = [cv2.imread(file) for file in sorted(glob.glob(path+no2+p1))]\n",
    "\n",
    "        #running Localization, Normalization,Enhancement and Feature Extraction on all the training images\n",
    "        boundary_train,centers_train=IrisLocalization(images_train)\n",
    "        normalized_train=IrisNormalization(boundary_train,centers_train)\n",
    "        enhanced_train=ImageEnhancement(normalized_train)\n",
    "        feature_vector_train=FeatureExtraction(enhanced_train)\n",
    "        #print(\"Training data processed.\")\n",
    "\n",
    "        images_test = [cv2.imread(file) for file in sorted(glob.glob(path+no1+p2))]\n",
    "        #running Localization, Normalization,Enhancement and Feature Extraction on all the testing images\n",
    "        boundary_test,centers_test=IrisLocalization(images_test)\n",
    "        normalized_test=IrisNormalization(boundary_test,centers_test)\n",
    "        enhanced_test=ImageEnhancement(normalized_test)\n",
    "        feature_vector_test=FeatureExtraction(enhanced_test)\n",
    "        #print(\"Testing data processed.\")\n",
    "\n",
    "        eu_dist,mh_dist,mk_dist,cos_dist,can_dist=IrisMatching(feature_vector_train,feature_vector_test)\n",
    "        #print(cos_dist)\n",
    "        #print(\"mean - \",mean(cos_dist))\n",
    "        l.append(mean(cos_dist))\n",
    "        \n",
    "    means.append(l)\n",
    "#print(means)\n",
    "threshold=[0.965,0.968,0.969,0.97]\n",
    "crr_cosine_all,fmr_all,fnmr_all=[],[],[]\n",
    "for t in threshold:\n",
    "    crr_cosine,fmr,fnmr=PerformanceEvaluation(means,t)\n",
    "    crr_cosine_all.append(crr_cosine)\n",
    "    fmr_all.append(fmr)\n",
    "    fnmr_all.append(fnmr)\n",
    "print(\"Performance evaluation\")\n",
    "dict1={'Threshold':threshold,'CRR cosine':crr_cosine_all,'FMR':fmr_all,'FNMR':fnmr_all}\n",
    "roc_table=pd.DataFrame(dict1)\n",
    "print(\"ROC Measures : \\n\")\n",
    "print(roc_table.iloc[0],\"\\n\")\n",
    "print(roc_table.iloc[1],\"\\n\")\n",
    "print(roc_table.iloc[2],\"\\n\")\n",
    "print(roc_table.iloc[3])\n",
    "\n",
    "#Plotting the ROC Curve\n",
    "plt.plot(fnmr_all,fmr_all)\n",
    "plt.title('ROC Curve')\n",
    "plt.ylabel('False Non-Match Rate')\n",
    "plt.xlabel('False Match Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b41407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
